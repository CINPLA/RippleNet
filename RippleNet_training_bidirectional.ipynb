{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubB9AcSmaT5z"
   },
   "source": [
    "# RippleNet_training_bidirectional\n",
    "Training of simple bidirectional recurrent neural network (RNN) implementation in `tensorflow.keras` using LSTM (long short-term memory) units to identify time of occurence of sharp wave ripple (SPW-R) events in temporal data.\n",
    "\n",
    "Author: Espen Hagen (<https://github.com/espenhgn>)\n",
    "\n",
    "LICENSE: <https://github.com/CINPLA/RippleNet/blob/master/LICENSE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1587983185985,
     "user": {
      "displayName": "Espen Hagen",
      "photoUrl": "",
      "userId": "16098989268258426650"
     },
     "user_tz": -120
    },
    "id": "NiELVop4aT54",
    "outputId": "1d1170dc-ed6e-4372-f78c-dfb71d289ccf"
   },
   "outputs": [],
   "source": [
    "# allow running on Google Colab for training using Google Drive for file access\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    %cd gdrive/My\\ Drive/Colab\\ Notebooks/RippleNet\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMwOuBEXaT6H"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUcZ1pzZaT6M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import colors\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import ripplenet.models\n",
    "import h5py\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1706,
     "status": "ok",
     "timestamp": 1587983186724,
     "user": {
      "displayName": "Espen Hagen",
      "photoUrl": "",
      "userId": "16098989268258426650"
     },
     "user_tz": -120
    },
    "id": "wOvpLagbaT6S",
    "outputId": "865a81d8-d94d-46ac-c7eb-7bd5ba8051f9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1700,
     "status": "ok",
     "timestamp": 1587983186725,
     "user": {
      "displayName": "Espen Hagen",
      "photoUrl": "",
      "userId": "16098989268258426650"
     },
     "user_tz": -120
    },
    "id": "DwjTugQJaT6Y",
    "outputId": "29c33870-4460-4709-ec8d-d148ae524b7b"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tz9QovhfaT6d"
   },
   "outputs": [],
   "source": [
    "# set random seeds with some additional environment variables to ensure deterministic output\n",
    "random_seed = 789\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['PYTHONHASHSEED']=str(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vm9oqmum3zby"
   },
   "outputs": [],
   "source": [
    "# select dataset (may have generated different sets.)\n",
    "dataset_index = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzZCG0OdaT6j"
   },
   "source": [
    "# Load training/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCKsK9lmkJK9"
   },
   "outputs": [],
   "source": [
    "# select species for training/validation data (mouse, rat or both)\n",
    "mouse = True\n",
    "rat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WxPYF3YkJLA"
   },
   "outputs": [],
   "source": [
    "# output destination\n",
    "output_folder = 'trained_networks'\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# prefix for trained network files (training loss/MSE, weights, `best' weights)\n",
    "rnn_prefix = 'ripplenet_bidirectional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZdjexMNkJLC"
   },
   "outputs": [],
   "source": [
    "if mouse:\n",
    "    # training and validation files\n",
    "    f_name_train = 'train_{:02}.h5'\n",
    "    f_name_val = 'validation_{:02}.h5'\n",
    "\n",
    "    # training data\n",
    "    f = h5py.File(os.path.join('data',  \n",
    "                               f_name_train.format(dataset_index)), \n",
    "                  'r')\n",
    "    X_train = np.expand_dims(f['X0'][:], -1)\n",
    "    Y_train = f['Y'][:]\n",
    "    f.close()\n",
    "\n",
    "    # validation data\n",
    "    f = h5py.File(os.path.join('data', \n",
    "                               f_name_val.format(dataset_index)), \n",
    "                  'r')\n",
    "    X_val = np.expand_dims(f['X0'][:], -1)\n",
    "    Y_val = f['Y'][:]\n",
    "    f.close()\n",
    "\n",
    "    # load some data for plotting\n",
    "    f = h5py.File(os.path.join('data',\n",
    "                               f_name_val.format(dataset_index)), 'r')\n",
    "    X0 = f['X0'][:]\n",
    "    X1 = f['X1'][:]\n",
    "    S = f['S'][:]\n",
    "    Y = f['Y'][:]\n",
    "    S_freqs = f['S_freqs'][:]\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7j9ekh6XkJLF"
   },
   "outputs": [],
   "source": [
    "# Add rat training/validation data to sets\n",
    "if rat and mouse:\n",
    "    # rat \n",
    "    f_name_train = 'train_tingley_{:02}.h5'\n",
    "    f_name_val = 'validation_tingley_{:02}.h5'\n",
    "\n",
    "    # training data\n",
    "    f = h5py.File(os.path.join('data', \n",
    "                            f_name_train.format(dataset_index)), \n",
    "                'r')\n",
    "    X_train = np.concatenate((X_train, np.expand_dims(f['X0'][:], -1)))\n",
    "    Y_train = np.concatenate((Y_train, f['Y'][:]))\n",
    "    f.close()\n",
    "\n",
    "    # validation data\n",
    "    f = h5py.File(os.path.join('data',  \n",
    "                            f_name_val.format(dataset_index)), \n",
    "                'r')\n",
    "    X_val = np.concatenate((X_val, np.expand_dims(f['X0'][:], -1)))\n",
    "    Y_val = np.concatenate((Y_val, f['Y'][:]))\n",
    "    f.close()\n",
    "\n",
    "    # load some data for plotting\n",
    "    f = h5py.File(os.path.join('data',\n",
    "                            f_name_val.format(dataset_index)), 'r')\n",
    "    X0 = np.concatenate((X0, f['X0'][:]))\n",
    "    X1 = np.concatenate((X1, f['X1'][:]))\n",
    "    S = np.concatenate((S, f['S'][:]))\n",
    "    Y = np.concatenate((Y, f['Y'][:]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWRDwjYDkJLI"
   },
   "outputs": [],
   "source": [
    "if rat and not mouse:\n",
    "    # rat \n",
    "    f_name_train = 'train_tingley_{:02}.h5'\n",
    "    f_name_val = 'validation_tingley_{:02}.h5'\n",
    "\n",
    "    # training data\n",
    "    f = h5py.File(os.path.join('data',  \n",
    "                               f_name_train.format(dataset_index)), \n",
    "                  'r')\n",
    "    X_train = np.expand_dims(f['X0'][:], -1)\n",
    "    Y_train = f['Y'][:]\n",
    "    f.close()\n",
    "\n",
    "    # validation data\n",
    "    f = h5py.File(os.path.join('data', \n",
    "                               f_name_val.format(dataset_index)), \n",
    "                  'r')\n",
    "    X_val = np.expand_dims(f['X0'][:], -1)\n",
    "    Y_val = f['Y'][:]\n",
    "    f.close()\n",
    "\n",
    "    # load some data for plotting\n",
    "    f = h5py.File(os.path.join('data', \n",
    "                               f_name_val.format(dataset_index)), 'r')\n",
    "    X0 = f['X0'][:]\n",
    "    X1 = f['X1'][:]\n",
    "    S = f['S'][:]\n",
    "    Y = f['Y'][:]\n",
    "    S_freqs = f['S_freqs'][:]\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Hevce8KkJLL"
   },
   "outputs": [],
   "source": [
    "# needed parameters\n",
    "Fs = 1250 # Hz, sampling freq\n",
    "time = np.arange(X0.shape[1]) / Fs\n",
    "\n",
    "# center raw data\n",
    "X0 = (X0.T - X0.mean(axis=-1)).T\n",
    "\n",
    "# total number of samples\n",
    "n_samples = X0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4691,
     "status": "ok",
     "timestamp": 1587983189800,
     "user": {
      "displayName": "Espen Hagen",
      "photoUrl": "",
      "userId": "16098989268258426650"
     },
     "user_tz": -120
    },
    "id": "VszoOq-WaT60",
    "outputId": "d2860cae-587a-4850-f70d-f093137111a5"
   },
   "outputs": [],
   "source": [
    "# plot all labels and raw data matrices\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(12, 12))\n",
    "axes[0].pcolormesh(time, np.arange(n_samples), Y[:, :, 0])\n",
    "axes[0].set_ylabel('#')\n",
    "axes[0].set_title('labels (y)')\n",
    "axes[1].pcolormesh(time, np.arange(n_samples), X0, vmin=-X0.std()*3, vmax=X0.std()*3)\n",
    "axes[1].set_ylabel('#')\n",
    "axes[1].set_xlabel('t (s)')\n",
    "axes[1].set_title('raw data (X)')\n",
    "for ax in axes:\n",
    "    ax.axis(ax.axis('tight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7787,
     "status": "ok",
     "timestamp": 1587983193021,
     "user": {
      "displayName": "Espen Hagen",
      "photoUrl": "",
      "userId": "16098989268258426650"
     },
     "user_tz": -120
    },
    "id": "xqGT2ICzaT64",
    "outputId": "c93f05cf-b126-470b-ba61-b2d3c3ca874a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot wavelet spectrograms vs. labels and raw data for some samples\n",
    "for i in range(5):\n",
    "    gs = GridSpec(2, 1)\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    ax0.plot(time, X0[i, ], label='$X(t)$')\n",
    "    ax0.plot(time, X1[i, ], label=r'$\\phi_\\mathrm{bp}(t)$')\n",
    "    ax0.plot(time, Y[i, :, 0], label='label ($y$)' )\n",
    "    ax0.legend(ncol=2)\n",
    "    ax0.axis(ax0.axis('tight'))\n",
    "    ax0.set_title('label, raw data and spectrograms')\n",
    "    plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[1:, 0], sharex=ax0)\n",
    "    vmin, vmax = np.exp(np.percentile(np.log(S), [1, 99]))\n",
    "    im = ax1.pcolormesh(time, S_freqs, S[i, ].T, norm=colors.LogNorm(vmin=vmin, vmax=vmax),\n",
    "                        cmap='inferno')\n",
    "    ax1.axis(ax1.axis('tight'))\n",
    "    ax1.set_ylabel('$f$ (Hz)')\n",
    "    ax1.set_xlabel('$t$ (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GF-Om-cnaT6-"
   },
   "source": [
    "# Set up recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_IG0v1tkJLj"
   },
   "outputs": [],
   "source": [
    "model = ripplenet.models.get_bidirectional_LSTM_model(input_shape=(None, X_train.shape[2]), \n",
    "                                                      layer_sizes=[20, 10, 6, 6],\n",
    "                                                      seed=random_seed+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9930,
     "status": "ok",
     "timestamp": 1587983195183,
     "user": {
      "displayName": "Espen Hagen",
      "photoUrl": "",
      "userId": "16098989268258426650"
     },
     "user_tz": -120
    },
    "id": "nqH3VcApaT7J",
    "outputId": "2d9c58cc-058e-4d22-ae3a-fe1cf5ccf65b"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IE_8BYTRz-4"
   },
   "outputs": [],
   "source": [
    "# plot_model(model, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu5rxBaaaT7N"
   },
   "outputs": [],
   "source": [
    "# model checkpoints when validation mse improves\n",
    "filepath = os.path.join(output_folder, '{}_best_random_seed{}.h5'.format(rnn_prefix, random_seed))\n",
    "checkpoint_best = keras.callbacks.ModelCheckpoint(filepath, monitor='val_mse', \n",
    "                                             verbose=1, save_best_only=True, \n",
    "                                             mode='min')\n",
    "callback_hist = keras.callbacks.CSVLogger(os.path.join(output_folder, '{}_history_random_seed{}.csv'.format(rnn_prefix, random_seed)))\n",
    "callbacks_list = [checkpoint_best, callback_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10117695,
     "status": "ok",
     "timestamp": 1587995123166,
     "user": {
      "displayName": "Espen Hagen",
      "photoUrl": "",
      "userId": "16098989268258426650"
     },
     "user_tz": -120
    },
    "id": "ktXzlvIeaT7S",
    "outputId": "a414e8a3-72bf-4597-bd62-e97201733122"
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=20, \n",
    "                    epochs=50, \n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOaPE2duWVjl"
   },
   "outputs": [],
   "source": [
    "# save history to a pickle so we can load it later\n",
    "with open(os.path.join(output_folder, '{}_history_random_seed{}.pkl'.format(rnn_prefix, random_seed)), 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1587995124068,
     "user": {
      "displayName": "Espen Hagen",
      "photoUrl": "",
      "userId": "16098989268258426650"
     },
     "user_tz": -120
    },
    "id": "jijEvsoEaT7X",
    "outputId": "f214f36f-2b74-4092-c1d8-9817a8ff8610"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.semilogy(history.history['loss'], '-o', label='loss')\n",
    "plt.semilogy(history.history['val_loss'], '-o', label='val_loss')\n",
    "plt.semilogy(history.history['mse'], '-o', label='mse')\n",
    "plt.semilogy(history.history['val_mse'], '-o', label='val_mse')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('training/validation MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLF11w-saT7a"
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(os.path.join(output_folder, '{}_random_seed{}.h5'.format(rnn_prefix, random_seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DaBPpQslYdBO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RippleNet_training_bidirectional.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
