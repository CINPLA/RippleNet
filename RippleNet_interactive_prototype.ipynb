{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow running on Google Colab for training, validation etc. \n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    %cd gdrive/My\\ Drive/Colab\\ Notebooks/NN_Ripple_Detection/neural_networks\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "from matplotlib import colors\n",
    "#import seaborn as sns\n",
    "#import pandas as pd\n",
    "from time import time, sleep\n",
    "import pickle\n",
    "#from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Tensorflow v2.0.0\n",
      "running on devices:\n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15334711968397369241\n",
      "]\n",
      "Num GPUs Available:  0\n",
      "GPU device:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print('running Tensorflow v{}'.format(tf.__version__))\n",
    "print('running on devices:\\n', device_lib.list_local_devices())\n",
    "print('Num GPUs Available: ', len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print('GPU device:\\n', tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seeds for reproducible results\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RippleNet instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_file': 'networks/blstm_model_raw_rat_LFP_random_seed1.h5', 'threshold': 0.44999999999999996, 'width': 0.0, 'distance': 62}\n"
     ]
    }
   ],
   "source": [
    "# load info on best model (path, threhsold settings)\n",
    "with open('best_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "    print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RippleNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 1)]         0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 20)          220       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 20)          80        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 10)          2210      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, None, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 10)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 12)          816       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 12)          48        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 12)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 12)          912       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 12)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 12)          48        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, None, 12)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1)           13        \n",
      "=================================================================\n",
      "Total params: 4,387\n",
      "Trainable params: 4,279\n",
      "Non-trainable params: 108\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the 'best' performing model on the validation sets\n",
    "model = keras.models.load_model(best_model['model_file'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#model = keras.models.load_model(os.path.join('networks', 'bgru_model_raw_rat_LFP_random_seed1.h5'))\n",
    "#model = keras.models.load_model(os.path.join('networks', 'blstm_model_raw_rat_LFP_random_seed1.h5'))\n",
    "model = keras.models.load_model(os.path.join('networks', 'blstm_v3_model_raw_rat_LFP_random_seed0.h5'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some needed parameters\n",
    "Fs = 1250 # Hz, sampling freq\n",
    "lag = int(100 * Fs / 1000) # 100 ms @ Fs\n",
    "\n",
    "# Threshold settings for detecting ripple events from prediction, \n",
    "threshold = best_model['threshold']\n",
    "distance = best_model['distance']\n",
    "width = best_model['width']\n",
    "\n",
    "# see scipy.signal.find_peaks documentation\n",
    "#threshold = 0.4 # detection threshold on the interval (0, 1)\n",
    "#distance = int(50 * Fs / 1000) # timesteps, distance*Fs/1000 peak interdistance in units of ms\n",
    "#width = 50 # timesteps, width*Fs/1000 peak width in units of ms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bandpass-filter LFP filter settings\n",
    "Wn = (150 / (Fs / 2), 250 / (Fs / 2)) # critical frequencies\n",
    "N = 2                                 # filter order\n",
    "b, a = ss.butter(N, Wn, btype='bandpass') # filter coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet parameters for spectrograms\n",
    "S_freqs = np.arange(100., 251, 10) # Hz, wavelet spectrogram frequencies\n",
    "\n",
    "#set up continuous wavelets\n",
    "w=6.\n",
    "s=1.\n",
    "\n",
    "#wavelets\n",
    "waveletfun = ss.morlet\n",
    "wavelets = []\n",
    "for i, freq in enumerate(S_freqs):\n",
    "    kwargs = {\n",
    "        'M' : int(2. * s * Fs * w / freq),\n",
    "        'w' : w,\n",
    "        's' : s,\n",
    "        'complete' : True,\n",
    "    }\n",
    "    wl = waveletfun(**kwargs)\n",
    "    wavelets.append(wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `HDF5` file with raw LFP trace for processing. The file must be structured as follows:\n",
    "```\n",
    "/<session_name>          Group                # group for session data\n",
    "/<session_name>/lfp      Dataset {753914}     # input LFP in units of mV [mandatory], float type\n",
    "/<session_name>/S        Dataset {753914, 16} # spectrogram [optional], float type\n",
    "/<session_name>/S_freqs  Dataset {16}         # spectrogram center frequencies [optional], float type\n",
    "/<session_name>/X1       Dataset {753914}     # signal (e.g., band-pass filtered LFP) [optional], float type\n",
    "/<session_name>/rippleLocs Dataset {86}       # ripple locations in units of time steps [optional], int type\n",
    "/<session_name>/run_speed Dataset {753914}    # run speed [optional], int/float type\n",
    "/<session_name>/y        Dataset {753914}     # one-hot encoding of ripple events [optional], float type\n",
    "\n",
    "/<session_name>/RippleNet Group               # group for RippleNet specific data [optional]\n",
    "/<session_name>/RippleNet/X Dataset {191, 251} # lfp segments, float type\n",
    "/<session_name>/RippleNet/X_S Dataset {191, 251, 16} # spectrograms, float type\n",
    "/<session_name>/RippleNet/X_bp Dataset {191, 251} # filtered lfp segments, float type\n",
    "/<session_name>/RippleNet/ripple_locations Dataset {191} # ripple locations, int type\n",
    "/<session_name>/RippleNet/confidence Dataset {191} # ripple strenght (y_hat at ripple), float type\n",
    "/<session_name>/RippleNet/ripple_labels Dataset {191} # ripple labels, bool type\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open file with complete LFP time series:\n",
    "Adapt `session` and `file_path` below accordingly. \n",
    "\n",
    "If `file_mode` equals `r+` RippleNet predictions (ripple locations) and  data segments  (lfp, lfp_bp, spectrograms) will be  stored in the file, if `file_mode` equals `r`, the input file will be left untouched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened file ../data/processed/m4029_session1.h5 (<HDF5 file \"m4029_session1.h5\" (mode r+)>)\n"
     ]
    }
   ],
   "source": [
    "file_mode = 'r+' \n",
    "session = 'm4029_session1'  # holdout dataset\n",
    "file_path = os.path.join('..', 'data', 'processed', '{}.h5'.format(session))\n",
    "f = h5py.File(file_path, file_mode)\n",
    "print('opened file {} ({})'.format(file_path, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run RippleNet on data\n",
    "Two operation modes are possible.  \n",
    "If `continuous_prediction==True` (not recommended for now) use entire time series as input,  \n",
    "if `continuous_prediction==False` (recommended) reshape input LFP into segments of lengths `Fs` (i.e., 1s) and use as input. \n",
    "\n",
    "This operation may take a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Switch or reshaping into 1s segments, running \n",
    "continuous_prediction = False\n",
    "\n",
    "# input must have correct shape (n_samples, n_timesteps, 1)\n",
    "#lfp = np.expand_dims(np.expand_dims(f[session]['lfp'], 0), -1)\n",
    "lfp = f[session]['lfp'][:]\n",
    "'''\n",
    "if continuous_prediction:\n",
    "    # Predict using entire dataset at once\n",
    "    y_hat = model.predict(np.expand_dims(np.expand_dims(lfp, 0), -1))\n",
    "else:\n",
    "    # Reshape time axis to segments of some duration\n",
    "    segment_length = int(0.5 * Fs) # Fs\n",
    "\n",
    "    # run predictions n times with shifts of length segment_length / n,\n",
    "    # then final output will be averaged\n",
    "    n = 5 # nicely divisible with Fs=1250\n",
    "    shift = int(segment_length / n)\n",
    "    container = []\n",
    "    for i in range(n):\n",
    "\n",
    "        # Reshape time axis to segments of segment_length duration.\n",
    "        # pad with zeros \n",
    "        lfp_reshaped = np.concatenate((np.expand_dims(np.expand_dims(lfp, 0), -1), \n",
    "                                       np.zeros((1, Fs - (lfp.size % Fs), 1))), axis=1)\n",
    "        lfp_reshaped = lfp_reshaped.reshape((-1, Fs, 1))\n",
    "\n",
    "        # run prediction on data\n",
    "        y_hat = model.predict(lfp_reshaped)\n",
    "\n",
    "        # free up some memory\n",
    "        del lfp_reshaped\n",
    "\n",
    "        # Reshape original size\n",
    "        y_hat = y_hat.reshape((1, -1, 1))[:, :lfp.size, :]\n",
    "\n",
    "# flatten prediction vector\n",
    "y_hat = y_hat.flatten()\n",
    "\n",
    "'''\n",
    "\n",
    "# Switch or reshaping input into segments, or running on full time series\n",
    "if continuous_prediction:\n",
    "    # Predict using entire dataset at once\n",
    "    Y_cont_pred = model.predict(np.expand_dims(np.expand_dims(lfp, 0), -1))\n",
    "else:\n",
    "    # Reshape time axis to segments of Fs duration\n",
    "    segment_length = int(0.5 * Fs) # Fs\n",
    "\n",
    "    # run predictions n times with shifts of length segment_length / n,\n",
    "    # then final output will be averaged\n",
    "    n = 5 # nicely divisible with Fs=1250\n",
    "    shift = int(segment_length / n)\n",
    "    container = []\n",
    "    for i in range(n):\n",
    "        lfp_reshaped = np.concatenate((np.zeros((1, i * shift, 1)), \n",
    "                                       np.expand_dims(np.expand_dims(lfp, 0), -1)), axis=1)\n",
    "\n",
    "        # pad with zeros \n",
    "        lfp_reshaped = np.concatenate((lfp_reshaped, \n",
    "                                         np.zeros((1, segment_length - \n",
    "                                                   (lfp_reshaped.size % segment_length), 1))), \n",
    "                                        axis=1)\n",
    "        \n",
    "        # reshape into segments of length  \n",
    "        lfp_reshaped = lfp_reshaped.reshape((-1, segment_length, 1))\n",
    "\n",
    "        # run prediction on data\n",
    "        y_hat = model.predict(lfp_reshaped)\n",
    "\n",
    "        # Reshape to zero-padded size\n",
    "        y_hat = y_hat.reshape((1, -1, 1))[:, :lfp_reshaped.size, :]\n",
    "\n",
    "        # strip elements that were padded with zeros\n",
    "        container.append(y_hat[:, i * shift:i * shift + lfp.size, :])\n",
    "\n",
    "    # average or median\n",
    "    y_hat = np.median(container, axis=0).flatten()\n",
    "\n",
    "    # remove intermediate predictions\n",
    "    del container, lfp_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_hat.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find peaks in the prediction `y_hat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_locations, _ = ss.find_peaks(y_hat, height=threshold, distance=distance, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove ripple locations in movement periods (within 0.5s of movement event)\n",
    "if 'run_speed' in list(f[session].keys()):\n",
    "    # smoothen run_speed by 1s boxcar filter:\n",
    "    run_speed = np.convolve(f[session]['run_speed'], ss.boxcar(Fs) / Fs, 'same')\n",
    "    # keep ripples where run_speed == 0:\n",
    "    ripple_locations = ripple_locations[run_speed[ripple_locations] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define `confidence` as value of y_hat at time of events\n",
    "# (so not in the strict sense as in statistics)\n",
    "confidence = y_hat[ripple_locations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get samples of LFPs etc. for each detected ripple event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(lfp, lfp_bp, lfp_S, ripple_locations, lag=100, Fs=1250):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    Returns:\n",
    "    --------\n",
    "    '''\n",
    "    # create arrays\n",
    "    X = [] # container for raw data segments\n",
    "    X_bp = [] # container for gamma-band data segments\n",
    "    X_S = []  # container for specgram\n",
    "    \n",
    "    sample_size = lag * 2 + 1\n",
    "\n",
    "    for ind in ripple_locations:\n",
    "        offset = -sample_size // 2        \n",
    "        \n",
    "        idx = np.arange(sample_size) + ind + offset\n",
    "        if idx.min() < 0:\n",
    "            idx -= idx.min()\n",
    "        elif idx.max() >= lfp.size:\n",
    "            idx = idx - (idx.max() - lfp.size + 1) \n",
    "        X.append(lfp[idx])\n",
    "        X_bp.append(lfp_bp[idx])\n",
    "        X_S.append(lfp_S[idx, ])\n",
    "        \n",
    "    # convert to numpy arrays, downcast to single precision\n",
    "    X = np.array(X).astype(np.float32)\n",
    "    X_bp = np.array(X_bp).astype(np.float32)\n",
    "    X_S = np.array(X_S).astype(np.float32)\n",
    "    \n",
    "    return X, X_bp, X_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch or compute bandpass-filtered LFP\n",
    "if 'X1' in list(f[session].keys()):\n",
    "    lfp_bp = f[session]['X1'][:]\n",
    "else:\n",
    "    lfp_bp = ss.filtfilt(b, a, f[session]['lfp'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for spectrograms\n",
    "lfp_S = np.empty((lfp.size, S_freqs.size), dtype=complex)\n",
    "\n",
    "#apply wavelets\n",
    "for i, wavelet in enumerate(wavelets):\n",
    "    lfp_S[:, i] = ss.convolve(lfp.flatten(), wavelet, 'same')\n",
    "\n",
    "# compute envelope\n",
    "lfp_S = np.abs(lfp_S).astype(np.float32)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get samples around ripple locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_bp, X_S = get_samples(lfp, lfp_bp, lfp_S, ripple_locations, lag=lag, Fs=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = (np.arange(lag * 2 + 1) - lag) * 1000 / Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = np.exp(np.percentile(np.log(X_S.flatten()), [1, 99]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot samples, reject noise events etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sorting order (either `chronological`, `confidence`, `confidence_reversed`, `random`, `None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_order = 'confidence'\n",
    "if sort_order is None or sort_order == 'chronological':\n",
    "    sorting = np.arange(X.shape[0])\n",
    "elif sort_order == 'random':\n",
    "    sorting = np.random.permutation(np.arange(X.shape[0]))\n",
    "elif sort_order == 'confidence':\n",
    "    sorting = np.argsort(confidence)[::-1]\n",
    "elif sort_order == 'confidence_reversed':\n",
    "    sorting = np.argsort(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RippleNetPlot:\n",
    "    '''Main object for figure, axes and mouse-click events'''\n",
    "    def __init__(self, ncols=10, figsize=(8,5)):\n",
    "\n",
    "        # create figure and axes\n",
    "        nrows = 3\n",
    "        \n",
    "        (self.fig, self.axes) = plt.subplots(nrows, ncols, sharex=True, sharey='row', figsize=figsize)\n",
    "        self.fig.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95, wspace=0.05)\n",
    "        \n",
    "        # annotate plots\n",
    "        self.axes[0, 0].set_ylabel('(mV)', labelpad=0)\n",
    "        self.axes[1, 0].set_ylabel('(mV)', labelpad=0)\n",
    "        self.axes[2, 0].set_ylabel('$f$ (Hz)', labelpad=0)\n",
    "        self.axes[2, 0].set_xticks([lags[0], 0, lags[-1]])\n",
    "        self.axes[2, 0].set_xticklabels([lags[0], 0])\n",
    "        self.axes[2, 0].set_xlabel(r'$\\tau$ (ms)', labelpad=0)\n",
    "\n",
    "        self.nrows = nrows\n",
    "        self.ncols = ncols\n",
    "\n",
    "        self._event_axes = []\n",
    "\n",
    "        self.rejected = []\n",
    "\n",
    "        self.button_presses = 0\n",
    "\n",
    "        self.cid = self.fig.canvas.mpl_connect('button_press_event', self.on_click)\n",
    "\n",
    "    '''def disconnect(self):\n",
    "        self.fig.canvas.mpl_disconnect(self.cid)'''\n",
    "\n",
    "    def on_click(self, event):\n",
    "        '''\n",
    "        Detects mouse click in axes\n",
    "        '''\n",
    "        if event.inaxes == axnext:\n",
    "            self._event_axes = []\n",
    "            return # ignore clicks on button\n",
    "\n",
    "        (_, col) = np.where(self.axes == event.inaxes)\n",
    "\n",
    "        if not event.inaxes in self._event_axes:\n",
    "            for ax in self.axes[:, col]:\n",
    "                self._event_axes.append(ax)\n",
    "\n",
    "            self.rejected.append(col[0] + self.button_presses * self.ncols)\n",
    "\n",
    "            event.inaxes.patch.set_facecolor('gray')\n",
    "        else:\n",
    "            for ax in self.axes[:, col]:\n",
    "                self._event_axes.remove(ax)\n",
    "\n",
    "            self.rejected.remove(col[0] + self.button_presses * self.ncols)\n",
    "\n",
    "            event.inaxes.patch.set_facecolor('white')\n",
    "\n",
    "        plt.gcf().canvas.draw()\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75f6883d3a94d9f821aa360ba8a80ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "# create interactive plot\n",
    "plot = RippleNetPlot()\n",
    "axes = plot.axes\n",
    "\n",
    "for j in range(plot.ncols):\n",
    "    try:\n",
    "        k = sorting[j]\n",
    "        plot.axes[0, j].plot(lags, X[k] - X[k].mean(), 'k', lw=0.5)\n",
    "        plot.axes[1, j].plot(lags, X_bp[k], 'k', lw=0.5)\n",
    "        plot.axes[2, j].pcolormesh(lags, S_freqs, X_S[k].T,\n",
    "                                   norm=colors.LogNorm(vmin=vmin, vmax=vmax),\n",
    "                                   cmap='inferno')\n",
    "        #plot.axes[0, j].set_title(r'$\\hat{y}=' + '{:.2f}'.format(np.round(confidence[k])) + r'$')\n",
    "    except IndexError:\n",
    "        plot.axes[0, j].axis('off')\n",
    "        plot.axes[1, j].axis('off')\n",
    "        plot.axes[2, j].axis('off')\n",
    "\n",
    "class ButtonPresses(object):\n",
    "    button_presses = 0\n",
    "\n",
    "    def next(self, event):\n",
    "        self.button_presses += 1\n",
    "\n",
    "        plot.button_presses = self.button_presses\n",
    "\n",
    "        for j in range(plot.ncols):\n",
    "            try:\n",
    "                k = sorting[self.button_presses * plot.ncols + j]\n",
    "                plot.axes[0, j].lines[0].set_ydata(X[k] - X[k].mean())\n",
    "                plot.axes[1, j].lines[0].set_ydata(X_bp[k])\n",
    "                plot.axes[0, j].axis(plot.axes[0, j].axis('tight'))\n",
    "                plot.axes[2, j].collections[0].set_array(X_S[k].T[:-1,:-1].ravel())\n",
    "            except IndexError:\n",
    "                plot.axes[0, j].lines.pop()\n",
    "                plot.axes[1, j].lines.pop()\n",
    "                plot.axes[2, j].collections.pop()\n",
    "                plot.axes[0, j].axis('off')\n",
    "                plot.axes[1, j].axis('off')\n",
    "                plot.axes[2, j].axis('off')\n",
    "\n",
    "        plt.gcf().canvas.draw()\n",
    "\n",
    "        return\n",
    "\n",
    "callback = ButtonPresses()\n",
    "axnext = plt.axes([0.8, 0.0, 0.1, 0.05])\n",
    "bnext = Button(axnext, 'Next')\n",
    "bnext.on_clicked(callback.next)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-47284cf05ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m \u001b[0;31m# ugly fix, don't continue interactiev plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise Exception # ugly fix, break execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of rejected (noise) events\n",
    "rejected = np.array(plot.rejected, dtype=int) \n",
    "rejected = rejected[rejected < ripple_locations.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate boolean label array for every ripple location (True - ripple event, False - noise event)\n",
    "ripple_labels = np.ones(ripple_locations.size, dtype=bool)\n",
    "ripple_labels[rejected] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 158, array([118]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripple_locations.size, ripple_labels.size, rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update HDF5 file with data\n",
    "if f.mode == 'r+':\n",
    "    grp = f[session].require_group('RippleNet')\n",
    "    for key, value in zip(['ripple_locations', 'confidence', 'ripple_labels', 'X', 'X_bp', 'X_S'], \n",
    "                          [ripple_locations, confidence, ripple_labels, X, X_bp, X_S]):\n",
    "        if key in list(grp.keys()):\n",
    "            del grp[key]\n",
    "        grp[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close file for reading/writing\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
