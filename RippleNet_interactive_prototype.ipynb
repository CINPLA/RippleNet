{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RippleNet_interactive_prototype\n",
    "Test implementation of user-interactive detection and rejection of detected SPW-R events using RippleNet.\n",
    "\n",
    "Author: Espen Hagen (<https://github.com/espenhgn>)\n",
    "\n",
    "LICENSE: <https://github.com/espenhgn/RippleNet/blob/master/LICENSE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow running on Google Colab for training, validation etc. \n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    %cd gdrive/My\\ Drive/Colab\\ Notebooks/RippleNet\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import h5py\n",
    "from matplotlib import colors\n",
    "from time import time, sleep\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print('running Tensorflow v{}'.format(tf.__version__))\n",
    "print('running on devices:\\n', device_lib.list_local_devices())\n",
    "print('Num GPUs Available: ', len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print('GPU device:\\n', tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seeds for reproducible results\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RippleNet instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load info on best model (path, threhsold settings)\n",
    "with open('best_model.pkl', 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "    print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 'best' performing model on the validation sets\n",
    "model = keras.models.load_model(best_model['model_file'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some needed parameters\n",
    "Fs = 1250 # Hz, sampling freq\n",
    "lag = int(100 * Fs / 1000) # 100 ms @ Fs\n",
    "\n",
    "# Threshold settings for detecting ripple events from prediction, \n",
    "threshold = best_model['threshold'] # detection threshold on the interval (0, 1)\n",
    "distance = best_model['distance']  # timesteps, distance*Fs/1000 peak interdistance in units of ms\n",
    "width = best_model['width']       # timesteps, width*Fs/1000 peak width in units of ms. \n",
    "# see scipy.signal.find_peaks documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bandpass-filter LFP filter settings\n",
    "Wn = (150 / (Fs / 2), 250 / (Fs / 2)) # critical frequencies\n",
    "N = 2                                 # filter order\n",
    "b, a = ss.butter(N, Wn, btype='bandpass') # filter coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet parameters for spectrograms\n",
    "S_freqs = np.arange(100., 251, 10) # Hz, wavelet spectrogram frequencies\n",
    "\n",
    "#set up continuous wavelets\n",
    "w=6.\n",
    "s=1.\n",
    "\n",
    "#wavelets\n",
    "waveletfun = ss.morlet\n",
    "wavelets = []\n",
    "for i, freq in enumerate(S_freqs):\n",
    "    kwargs = {\n",
    "        'M' : int(2. * s * Fs * w / freq),\n",
    "        'w' : w,\n",
    "        's' : s,\n",
    "        'complete' : True,\n",
    "    }\n",
    "    wl = waveletfun(**kwargs)\n",
    "    wavelets.append(wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `HDF5` file with raw LFP trace for processing. The file must be structured as follows:\n",
    "```\n",
    "/<session_name>          Group                # group for session data\n",
    "/<session_name>/lfp      Dataset {753914}     # input LFP in units of mV [mandatory], float type\n",
    "/<session_name>/S        Dataset {753914, 16} # spectrogram [optional], float type\n",
    "/<session_name>/S_freqs  Dataset {16}         # spectrogram center frequencies [optional], float type\n",
    "/<session_name>/X1       Dataset {753914}     # signal (e.g., band-pass filtered LFP) [optional], float type\n",
    "/<session_name>/rippleLocs Dataset {86}       # ripple locations in units of time steps [optional], int type\n",
    "/<session_name>/run_speed Dataset {753914}    # run speed [optional], int/float type\n",
    "/<session_name>/y        Dataset {753914}     # one-hot encoding of ripple events [optional], float type\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open file with complete LFP time series:\n",
    "Adapt `session` and `file_path` below accordingly. \n",
    "\n",
    "If `file_mode` equals `r+` RippleNet predictions (ripple locations) and  data segments  (lfp, lfp_bp, spectrograms) will be  stored in the file, if `file_mode` equals `r`, the input file will be left untouched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mode = 'r' \n",
    "session = 'm4029_session1'  # holdout dataset\n",
    "file_path = os.path.join('data', '{}.h5'.format(session))\n",
    "f = h5py.File(file_path, file_mode)\n",
    "print('opened file {} ({})'.format(file_path, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run RippleNet on data\n",
    "Two operation modes are possible.  \n",
    "If `continuous_prediction==True` (not recommended for now) use entire time series as input,  \n",
    "if `continuous_prediction==False` (recommended) reshape input LFP into segments of lengths `Fs` (i.e., 1s) and use as input. \n",
    "\n",
    "This operation may take a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Switch or reshaping into 1s segments, running \n",
    "continuous_prediction = False\n",
    "\n",
    "# input must have correct shape (n_samples, n_timesteps, 1)\n",
    "lfp = f[session]['lfp'][:]\n",
    "\n",
    "# Switch or reshaping input into segments, or running on full time series\n",
    "if continuous_prediction:\n",
    "    # Predict using entire dataset at once\n",
    "    Y_cont_pred = model.predict(np.expand_dims(np.expand_dims(lfp, 0), -1))\n",
    "else:\n",
    "    # Reshape time axis to segments of Fs duration\n",
    "    segment_length = int(0.5 * Fs) # Fs\n",
    "\n",
    "    # run predictions n times with shifts of length segment_length / n,\n",
    "    # then final output will be averaged\n",
    "    n = 5 # nicely divisible with Fs=1250\n",
    "    shift = int(segment_length / n)\n",
    "    container = []\n",
    "    for i in range(n):\n",
    "        lfp_reshaped = np.concatenate((np.zeros((1, i * shift, 1)), \n",
    "                                       np.expand_dims(np.expand_dims(lfp, 0), -1)), axis=1)\n",
    "\n",
    "        # pad with zeros \n",
    "        lfp_reshaped = np.concatenate((lfp_reshaped, \n",
    "                                         np.zeros((1, segment_length - \n",
    "                                                   (lfp_reshaped.size % segment_length), 1))), \n",
    "                                        axis=1)\n",
    "        \n",
    "        # reshape into segments of length  \n",
    "        lfp_reshaped = lfp_reshaped.reshape((-1, segment_length, 1))\n",
    "\n",
    "        # run prediction on data\n",
    "        y_hat = model.predict(lfp_reshaped)\n",
    "\n",
    "        # Reshape to zero-padded size\n",
    "        y_hat = y_hat.reshape((1, -1, 1))[:, :lfp_reshaped.size, :]\n",
    "\n",
    "        # strip elements that were padded with zeros\n",
    "        container.append(y_hat[:, i * shift:i * shift + lfp.size, :])\n",
    "\n",
    "    # average or median\n",
    "    y_hat = np.median(container, axis=0).flatten()\n",
    "\n",
    "    # remove intermediate predictions\n",
    "    del container, lfp_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_hat.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find peaks in the prediction `y_hat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_locations, _ = ss.find_peaks(y_hat, height=threshold, distance=distance, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove ripple locations in movement periods (within 0.5s of movement event)\n",
    "if 'run_speed' in list(f[session].keys()):\n",
    "    # smoothen run_speed by 1s boxcar filter:\n",
    "    run_speed = np.convolve(f[session]['run_speed'], ss.boxcar(Fs) / Fs, 'same')\n",
    "    # keep ripples where run_speed == 0:\n",
    "    ripple_locations = ripple_locations[run_speed[ripple_locations] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define `probability` as value of y_hat at time of events\n",
    "# (so not in the strict sense as in statistics)\n",
    "probability = y_hat[ripple_locations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get samples of LFPs etc. for each detected ripple event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(lfp, lfp_bp, lfp_S, ripple_locations, lag=100, Fs=1250):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    Returns:\n",
    "    --------\n",
    "    '''\n",
    "    # create arrays\n",
    "    X = [] # container for raw data segments\n",
    "    X_bp = [] # container for gamma-band data segments\n",
    "    X_S = []  # container for specgram\n",
    "    \n",
    "    sample_size = lag * 2 + 1\n",
    "\n",
    "    for ind in ripple_locations:\n",
    "        offset = -sample_size // 2        \n",
    "        \n",
    "        idx = np.arange(sample_size) + ind + offset\n",
    "        if idx.min() < 0:\n",
    "            idx -= idx.min()\n",
    "        elif idx.max() >= lfp.size:\n",
    "            idx = idx - (idx.max() - lfp.size + 1) \n",
    "        X.append(lfp[idx])\n",
    "        X_bp.append(lfp_bp[idx])\n",
    "        X_S.append(lfp_S[idx, ])\n",
    "        \n",
    "    # convert to numpy arrays, downcast to single precision\n",
    "    X = np.array(X).astype(np.float32)\n",
    "    X_bp = np.array(X_bp).astype(np.float32)\n",
    "    X_S = np.array(X_S).astype(np.float32)\n",
    "    \n",
    "    return X, X_bp, X_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch or compute bandpass-filtered LFP\n",
    "if 'X1' in list(f[session].keys()):\n",
    "    lfp_bp = f[session]['X1'][:]\n",
    "else:\n",
    "    lfp_bp = ss.filtfilt(b, a, f[session]['lfp'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for spectrograms\n",
    "lfp_S = np.empty((lfp.size, S_freqs.size), dtype=complex)\n",
    "\n",
    "#apply wavelets\n",
    "for i, wavelet in enumerate(wavelets):\n",
    "    lfp_S[:, i] = ss.convolve(lfp.flatten(), wavelet, 'same')\n",
    "\n",
    "# compute envelope\n",
    "lfp_S = np.abs(lfp_S).astype(np.float32)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get samples around ripple locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_bp, X_S = get_samples(lfp, lfp_bp, lfp_S, ripple_locations, lag=lag, Fs=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = (np.arange(lag * 2 + 1) - lag) * 1000 / Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = np.exp(np.percentile(np.log(X_S.flatten()), [1, 99]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot samples, reject noise events etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sorting order (either `chronological`, `probability`, `probability_reversed`, `random`, `None`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_order = 'random'\n",
    "if sort_order is None or sort_order == 'chronological':\n",
    "    sorting = np.arange(X.shape[0])\n",
    "elif sort_order == 'random':\n",
    "    sorting = np.random.permutation(np.arange(X.shape[0]))\n",
    "elif sort_order == 'probability':\n",
    "    sorting = np.argsort(probability)[::-1]\n",
    "elif sort_order == 'probability_reversed':\n",
    "    sorting = np.argsort(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RippleNetPlot:\n",
    "    '''Main object for figure, axes and mouse-click events'''\n",
    "    def __init__(self, ncols=10, figsize=(9,5)):\n",
    "\n",
    "        # create figure and axes\n",
    "        nrows = 3\n",
    "        \n",
    "        (self.fig, self.axes) = plt.subplots(nrows, ncols, sharex=True, sharey='row', figsize=figsize)\n",
    "        self.fig.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95, wspace=0.05)\n",
    "        \n",
    "        # annotate plots\n",
    "        self.axes[0, 0].set_ylabel('(mV)', labelpad=0)\n",
    "        self.axes[1, 0].set_ylabel('(mV)', labelpad=0)\n",
    "        self.axes[2, 0].set_ylabel('$f$ (Hz)', labelpad=0)\n",
    "        self.axes[2, 0].set_xticks([lags[0], 0, lags[-1]])\n",
    "        self.axes[2, 0].set_xticklabels([lags[0], 0])\n",
    "        self.axes[2, 0].set_xlabel(r'$\\tau$ (ms)', labelpad=0)\n",
    "        \n",
    "        self.axes[0, 0].set_ylim(-0.5, 0.5)\n",
    "        self.axes[1, 0].set_ylim(-0.1, 0.1)\n",
    "\n",
    "        self.nrows = nrows\n",
    "        self.ncols = ncols\n",
    "\n",
    "        self._event_axes = []\n",
    "\n",
    "        self.rejected = []\n",
    "\n",
    "        self.button_presses = 0\n",
    "\n",
    "        self.cid = self.fig.canvas.mpl_connect('button_press_event', self.on_click)\n",
    "\n",
    "    '''def disconnect(self):\n",
    "        self.fig.canvas.mpl_disconnect(self.cid)'''\n",
    "\n",
    "    def on_click(self, event):\n",
    "        '''\n",
    "        Detects mouse click in axes\n",
    "        '''\n",
    "        if event.inaxes == axnext:\n",
    "            #for ax in self._event_axes:\n",
    "            #    c\n",
    "            self._event_axes = []\n",
    "            return # ignore clicks on button\n",
    "\n",
    "        (_, col) = np.where(self.axes == event.inaxes)\n",
    "\n",
    "        if not event.inaxes in self._event_axes:\n",
    "            for ax in self.axes[:, col]:\n",
    "                self._event_axes.append(ax)\n",
    "\n",
    "            self.rejected.append(col[0] + self.button_presses * self.ncols)\n",
    "\n",
    "            event.inaxes.patch.set_facecolor('gray')\n",
    "        else:\n",
    "            for ax in self.axes[:, col]:\n",
    "                self._event_axes.remove(ax)\n",
    "\n",
    "            self.rejected.remove(col[0] + self.button_presses * self.ncols)\n",
    "\n",
    "            event.inaxes.patch.set_facecolor('white')\n",
    "\n",
    "        plt.gcf().canvas.draw()\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "# create interactive plot\n",
    "plot = RippleNetPlot(ncols=5)\n",
    "axes = plot.axes\n",
    "\n",
    "for j in range(plot.ncols):\n",
    "    try:\n",
    "        k = sorting[j]\n",
    "        plot.axes[0, j].plot(lags, X[k] - X[k].mean(), 'k', lw=0.5)\n",
    "        plot.axes[1, j].plot(lags, X_bp[k], 'k', lw=0.5)\n",
    "        plot.axes[2, j].pcolormesh(lags, S_freqs, X_S[k].T,\n",
    "                                   norm=colors.LogNorm(vmin=vmin, vmax=vmax),\n",
    "                                   cmap='inferno')\n",
    "        #plot.axes[0, j].set_title(r'$\\hat{y}=' + '{:.2f}'.format(np.round(probability[k])) + r'$')\n",
    "    except IndexError:\n",
    "        plot.axes[0, j].axis('off')\n",
    "        plot.axes[1, j].axis('off')\n",
    "        plot.axes[2, j].axis('off')\n",
    "\n",
    "class ButtonPresses(object):\n",
    "    button_presses = 0\n",
    "\n",
    "    def next(self, event):\n",
    "        self.button_presses += 1\n",
    "\n",
    "        plot.button_presses = self.button_presses\n",
    "\n",
    "        for j in range(plot.ncols):\n",
    "            try:\n",
    "                k = sorting[self.button_presses * plot.ncols + j]\n",
    "                plot.axes[0, j].lines[0].set_ydata(X[k] - X[k].mean())\n",
    "                plot.axes[1, j].lines[0].set_ydata(X_bp[k])\n",
    "                plot.axes[0, j].axis(plot.axes[0, j].axis('tight'))\n",
    "                plot.axes[2, j].collections[0].set_array(X_S[k].T[:-1,:-1].ravel())\n",
    "            except IndexError:\n",
    "                plot.axes[0, j].lines.pop()\n",
    "                plot.axes[1, j].lines.pop()\n",
    "                plot.axes[2, j].collections.pop()\n",
    "                plot.axes[0, j].axis('off')\n",
    "                plot.axes[1, j].axis('off')\n",
    "                plot.axes[2, j].axis('off')\n",
    "\n",
    "        \n",
    "        for ax in plot.axes.flatten():\n",
    "            ax.patch.set_facecolor('white')\n",
    "        plt.gcf().canvas.draw()\n",
    "\n",
    "        return\n",
    "\n",
    "callback = ButtonPresses()\n",
    "axnext = plt.axes([0.8, 0.0, 0.1, 0.05])\n",
    "bnext = Button(axnext, 'Next')\n",
    "bnext.on_clicked(callback.next)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process output\n",
    "Dump label times and status to `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raise Exception # ugly, break execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of rejected (noise) events\n",
    "rejected = np.array(plot.rejected, dtype=int) \n",
    "rejected = rejected[rejected < ripple_locations.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate boolean label array for every ripple location (True - ripple event, False - noise event)\n",
    "ripple_labels = np.ones(ripple_locations.size, dtype=bool)\n",
    "ripple_labels[sorting[rejected]] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=dict(rippleLocs=ripple_locations[sorting], ripple=ripple_labels))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('{}_ripples.csv'.format(session), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
